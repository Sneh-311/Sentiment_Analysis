{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db0fe355-6867-45d7-acb4-204e54ea88e1",
   "metadata": {},
   "source": [
    "<span style=\"font-size:24px; font-weight:bold;\">SENTIMENT ANALYSIS ON REVIEWS GIVEN BY VIEWERS ON IMDB</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8bf9a6-bc0e-4ce3-85fe-a019d03aec89",
   "metadata": {},
   "source": [
    "The Dataset and Problem Statement:\n",
    "In this notebook, we will work with a dataset of 50,000 movie reviews from IMDB. The dataset consists of two columns: \"review\" and \"sentiment.\" These columns will help us determine whether a given movie review is positive or negative.\n",
    "\n",
    "Problem Objective:\n",
    "Our aim is to identify the most suitable machine learning model for predicting the sentiment (positive or negative) based on the content of a movie review."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64110292-89df-45d2-8083-a0223462d9fe",
   "metadata": {},
   "source": [
    "<img src=\"sentiment.png\" alt=\"Galaxy Image\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cc41e8-42f7-41a4-bf53-23cd66878315",
   "metadata": {},
   "source": [
    "<span style=\"font-size:24px; font-weight:bold;\">Importing the necessary libraries</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a0b7cdc-bf87-4b7d-8c12-f3d24116c022",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5430db73-4d2b-444b-9fd4-d7aff093a14d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# Download NLTK stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12607ee-d1e0-4cab-a4ef-f50738eae0d1",
   "metadata": {},
   "source": [
    "<span style=\"font-size:24px; font-weight:bold;\">Loading the dataset</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24c0453b-0322-4ea2-89c8-9606bd6aa53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(\"IMDB Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbb0982b-c2bc-45dd-a93d-bc9e1847a07d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71833760-16d7-4f80-86d3-544daa3421c5",
   "metadata": {},
   "source": [
    "<span style=\"font-size:24px; font-weight:bold;\">Exploratory Data Analysis</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd693eb9-1ccd-46e1-b1e9-1d0e4606ead2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>49582</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Loved today's show!!! It was a variety and not...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>5</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   review sentiment\n",
       "count                                               50000     50000\n",
       "unique                                              49582         2\n",
       "top     Loved today's show!!! It was a variety and not...  positive\n",
       "freq                                                    5     25000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Summary of the dataset\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8d9bc89-af94-4e23-b9b5-5f192b9a934c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "positive    25000\n",
       "negative    25000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sentiment count\n",
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b030fc13-66a8-4fea-8974-1493cd1762d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "review       0\n",
      "sentiment    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for null values in the dataset\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62f80d99-56b3-4198-9acc-bf86c7e5f899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to binary (0 = negative, 1 = positive)\n",
    "df['sentiment'] = df['sentiment'].map({'positive': 1, 'negative': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "435872c0-3270-4d3c-b8d1-b1b05f3d9c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract reviews and sentiments\n",
    "X = df['review']  # Features (reviews)\n",
    "y = df['sentiment']  # Labels (sentiments)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a448c6-3f7e-4ef9-b656-44c4655486e5",
   "metadata": {},
   "source": [
    "<span style=\"font-size:24px; font-weight:bold;\">Text Preprocessing</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3bfc6cf0-452c-42f7-8718-2c98ec986d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "# Define stop_words as a list\n",
    "stop_words = list(stopwords.words('english'))  # Ensure it's a list\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=stop_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "82d85031-e919-443b-b63d-6b9beb046bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Create a TfidfVectorizer with stopwords removal\n",
    "vectorizer = TfidfVectorizer(stop_words=stop_words)\n",
    "\n",
    "# Fit the model on the training data and transform both train and test sets\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e337e5-a01f-4b86-9321-dea75efc1b50",
   "metadata": {},
   "source": [
    "<span style=\"font-size:24px; font-weight:bold;\">Model Training</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8122cfdb-4822-4aa7-b020-6a2373d3a9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train_vectorized, y_train)\n",
    "y_pred = model.predict(X_test_vectorized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a35783-3469-4fb2-94ea-ac52876950f7",
   "metadata": {},
   "source": [
    "<span style=\"font-size:24px; font-weight:bold;\">Results</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "57e2e766-74bb-474d-a390-6757319bb37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[4365  596]\n",
      " [ 437 4602]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ef1339-0c1e-48c6-8e85-b987cdee275c",
   "metadata": {},
   "source": [
    "This confusion matrix represents the performance of a classification model on a dataset. The matrix is structured as follows:\n",
    "\n",
    "4365 (True Negatives - TN): The model correctly predicted negative class (0).\n",
    "\n",
    "596 (False Positives - FP): The model incorrectly predicted positive class (1) when it was actually negative (0).\n",
    "\n",
    "437 (False Negatives - FN): The model incorrectly predicted negative class (0) when it was actually positive (1).\n",
    "\n",
    "4602 (True Positives - TP): The model correctly predicted positive class (1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "86f6d1e5-d8d7-44eb-906d-5c240c9fe478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8967\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.88      0.89      4961\n",
      "           1       0.89      0.91      0.90      5039\n",
      "\n",
      "    accuracy                           0.90     10000\n",
      "   macro avg       0.90      0.90      0.90     10000\n",
      "weighted avg       0.90      0.90      0.90     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict the sentiment on the test set\n",
    "y_pred = model.predict(X_test_vectorized)\n",
    "\n",
    "# Calculate accuracy and print classification report\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6979b5c0-29cc-4214-b3aa-50d2c61dc697",
   "metadata": {},
   "source": [
    "This classification report provides key evaluation metrics for a binary classification model.\n",
    "\n",
    "Accuracy (0.8967 or ~90%) indicates that the model correctly classifies about 90% of the total 10,000 samples.\n",
    "    \n",
    "Precision (0.91 for class 0, 0.89 for class 1) represents the proportion of correctly predicted positive (or negative) samples out of all predicted positives (or negatives), meaning class 0 is slightly more precise.\n",
    "    \n",
    "Recall (0.88 for class 0, 0.91 for class 1) shows how well the model identifies all actual positive (or negative) samples; here, class 1 is captured slightly better than class 0.\n",
    "                                                                                                                         \n",
    "F1-score (0.89 for class 0, 0.90 for class 1) balances precision and recall, with both classes performing similarly.\n",
    "                                                                                                                         \n",
    "Macro average (0.90 across precision, recall, and F1-score) treats both classes equally, while the weighted average (0.90) adjusts for class imbalances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f204d64-279c-4cef-81a1-fe0505d36933",
   "metadata": {},
   "source": [
    "<span style=\"font-size:24px; font-weight:bold;\">Conclusion</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d261b002-472c-49ae-9898-b996af7735db",
   "metadata": {},
   "source": [
    "The sentiment analysis model, trained with logistic regression, achieved an accuracy of 0.90, demonstrating a strong ability to classify sentiment accurately. \n",
    "Both precision and recall were well-balanced, with values close to 0.90 for both classes, leading to an F1-score of 0.90 for each class, indicating the model's robustness in handling positive and negative sentiment classifications effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667279e1-a297-425e-9305-5637a9d38a32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
